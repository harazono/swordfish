# 共通設定
input_file                  = "SRR10238608.fasta"
input_file_base             = input_file.split(".")[0]
primer3_config_path         = "./primer3_config/normal_config"
primer3_config_display_name = "normal_config"
blastn_config               = "blastn_config"
taxon_ids                   = "taxon_ids_to_be_ignored.txt"
target_db_filepath          = "target_dbs.txt"
margin_size                 = "0"
threshold                   = "1000" #リードのカバレッジと分割数に応じて適宜変える←seqkit statsで調べてから動的に変える？面倒かも？
home                        = "/home/harazono"
primer3_result_parser_path  = "/home/harazono/Species_specific_DNA_marker/swordfish_test/swordfish/util/primer3_result_parser.py"
discard_primes_path         = "/home/harazono/Species_specific_DNA_marker/swordfish_test/swordfish/util/discard_trapped_primers.py"
ngs_read_part_size          = 63
lr_tuple_part_size          = 20

ngs_read_indice = [f"{i:03}" for i in range(1, ngs_read_part_size + 1)]
lr_tuple_indice = [f"{i:03}" for i in range(1, lr_tuple_part_size + 1)]

def load_target_dbs():
    with open(target_db_filepath) as f:
        return [line.strip() for line in f]
tgt_db_name_fullpath = load_target_dbs()
tgt_db_names         = [x.split("/")[-1] for x in tgt_db_name_fullpath]
dbname2fullpath_dict = {x.split("/")[-1]:x for x in tgt_db_name_fullpath}


rule all:
    input:
        # expand(f"lr_tuples/{threshold}/{{sample}}.bin", sample=ngs_read_indice),
        # expand(f"results_of_primer3_{primer3_config_display_name}/{threshold}/{threshold}_{{sample}}.primer3_out", sample=lr_tuple_indice),
        # expand(f"results_of_primer3_{primer3_config_display_name}_fasta/{threshold}/{threshold}_{{sample}}.fa", sample=lr_tuple_indice),
        # expand(f"results_of_primer3_{primer3_config_display_name}_json/{threshold}/{threshold}_{{sample}}.json", sample=lr_tuple_indice),
        # expand(f"results_of_blastn_{primer3_config_display_name}/{threshold}/{{sample}}/each/{{db_name}}.blastn_out.gz",
        #         db_name=[db.split("/")[-1] for db in tgt_db_names],
        #         sample=lr_tuple_indice),
        # expand(f"results_of_blastn_{primer3_config_display_name}/{threshold}/{{sample}}/concatenated.blastn_out.gz", sample=lr_tuple_indice),
        expand(f"results_of_discarding_{primer3_config_display_name}/{threshold}/{{sample}}/discard_results.finalist.tsv", sample = lr_tuple_indice),
        expand(f"results_of_discarding_{primer3_config_display_name}/{threshold}/{{sample}}/discard_results.finalist_name.txt", sample = lr_tuple_indice),
        expand(f"results_of_discarding_{primer3_config_display_name}/{threshold}/{{sample}}/discard_results.report", sample = lr_tuple_indice),



rule split_reads:
    # ToDo
    # メモリ使用量、要求スレッド数のチューニング
    input:
        input_file
    output:
        expand(f"ngs_reads/{input_file_base}.part_{{sample}}.fasta", sample=ngs_read_indice)
    params:
        ngs_read_part_size=ngs_read_part_size,
        home=home
    resources:
        mem_mb=1024*32
    threads: 8
    shell:
        """
        export PATH={home}/miniconda3/bin:$PATH
        export LD_LIBRARY_PATH={home}/miniconda3/pkgs/libffi-3.3-he6710b0_2/lib/:$LD_LIBRARY_PATH
        mkdir -p reads
        seqkit split -j 8 -p {ngs_read_part_size} {input} --out-dir reads
        """


rule count_lr_tuple:
    # ToDo
    # メモリ使用量、要求スレッド数のチューニング
    # count_lr_tupleをscripts以下に置く
    # count_lr_tupleの引数をチェックする
    # mergin sizeとthresholdは、レポートファイルに書き出すことを考えるとSnakemakeの変数で持っておきたい
    # stderrに引数を全部出力する（もうやってるかも）
    # target/release/search_primer
    # -o, --output NAME   set output file name
    # -t, --thread THREAD number of threads to use for radix sort. default value
    #                     is 8.
    # -a, --threshold THRESHOLD
    #                     threshold of occurence. default value is 1000.
    # -m, --margin_size MARGIN_SIZE
    #                     margin between l and r segments. default value is 0.
    # -b, --binary        outputs binary file
    # -r, --only-num      outputs only total number of lr-tuple.
    # -h, --help          print this help menu
    input:
        reads=f"ngs_reads/{input_file_base}.part_{{sample}}.fasta"
    output:
        lr_tuples=f"lr_tuples/{threshold}/{{sample}}.bin"
    params:
        threshold=threshold,
        margin_size=margin_size,
    resources:
        mem_mb=1024*24*8,
    threads: 8
    shell:
        """
        mkdir -p lr_tuples/{params.threshold}
        scripts/search_primer {input.reads} -o {output.lr_tuples} -t {threads} -a {params.threshold} -m {params.margin_size} -b
        """


rule lr_tuple_binary_merge_and_split:
    input:
        lr_tuples=expand(f"lr_tuples/{threshold}/{{sample}}.bin", sample=ngs_read_indice),
    output:
        lr_tuples_unique=expand(f"lr_tuples_unique/{threshold}/{threshold}_{{sample}}.bin", sample=lr_tuple_indice)
    params:
        merged_file=f"temp/merged_lr_tuples_{threshold}.bin"
    resources:
        mem_mb=1024*8,
    threads: 1
    shell:
        """
        export PATH=/home/harazono/miniconda3/bin:$PATH
        export LD_LIBRARY_PATH=~/miniconda3/pkgs/libffi-3.3-he6710b0_2/lib/:$LD_LIBRARY_PATH
        mkdir -p lr_tuples_unique temp
        # 各入力ファイルに対して -i オプションを付けてマージコマンドを構成
        merge_cmd=$(echo -n 'scripts/u128_binary_merge'; for f in {input.lr_tuples}; do echo -n " -i $f"; done; echo -n " -o {params.merged_file}")
        echo "Running: $merge_cmd"
        bash -c "$merge_cmd"

        # マージされたファイルを指定された数に分割する
        mkdir -p lr_tuples_unique/{threshold}
        scripts/u128_binary_split -i {params.merged_file} -n {lr_tuple_part_size} -o lr_tuples_unique/{threshold}/{threshold}

        # 中間マージファイルを削除
        rm {params.merged_file}
        """


rule primer3_caller:
    #    $ ./target/release/primer3_caller -h
    #    Usage: ./target/release/primer3_caller FILE 
    #
    #    Options:
    #    -h, --help          print this help menu
    #    -t, --thread THREAD number of thread to use for radix sort. default value
    #                        is 8.
    #    -c, --config CONFIG config file for primer3_core.
    #    -o, --output OUTPUT output file name for primer3 results
    #    -m, --tmpfile TEMP  set temporary file name prefix
    input:
        lr_tuples=f"lr_tuples_unique/{threshold}/{threshold}_{{sample}}.bin"
    output:
        primer3_out=f"results_of_primer3_{primer3_config_display_name}/{threshold}/{threshold}_{{sample}}.primer3_out"
    params:
        primer3_config_display_name=primer3_config_display_name,
        primer3_config_path=primer3_config_path
    resources:
        mem_mb=1024*4*8,
    threads: 8
    shell:
        """
        export PATH=/home/harazono/miniconda3/bin:$PATH
        export LD_LIBRARY_PATH=~/miniconda3/pkgs/libffi-3.3-he6710b0_2/lib/:$LD_LIBRARY_PATH
        mkdir -p results_of_primer3_{params.primer3_config_display_name}/{threshold}
        scripts/primer3_caller {input.lr_tuples} -o {output.primer3_out} -c {params.primer3_config_path} -t {threads}
        if [ ! -s {output.primer3_out} ]; then
            rm -f {output.primer3_out}
            exit 1
        fi
        """

rule results_of_primer3_to_fasta:
    input:
        primer3_out=f"results_of_primer3_{primer3_config_display_name}/{threshold}/{threshold}_{{sample}}.primer3_out"
    output:
        fasta=f"results_of_primer3_{primer3_config_display_name}_fasta/{threshold}/{threshold}_{{sample}}.fa",
    params:
        fasta_dir = f"results_of_primer3_{primer3_config_display_name}_fasta/{threshold}",
        primer3_result_parser_path = primer3_result_parser_path
    resources:
        mem_mb=1024*16,
    shell:
        """
        mkdir -p {params.fasta_dir}
        {primer3_result_parser_path} {input.primer3_out} --fasta -o {output.fasta}
        """

rule results_of_primer3_to_json:
    input:
        primer3_out=f"results_of_primer3_{primer3_config_display_name}/{threshold}/{threshold}_{{sample}}.primer3_out"
    output:
        json=f"results_of_primer3_{primer3_config_display_name}_json/{threshold}/{threshold}_{{sample}}.json",
    params:
        json_dir = f"results_of_primer3_{primer3_config_display_name}_json/{threshold}",
        primer3_result_parser_path = primer3_result_parser_path
    resources:
        mem_mb=1024*16,
    shell:
        """
        mkdir -p {params.json_dir}
        {primer3_result_parser_path} {input.primer3_out} -o {output.json}
        """


rule blast_search:
    input:
        fasta=f"results_of_primer3_{primer3_config_display_name}_fasta/{threshold}/{threshold}_{{sample}}.fa",
    output:
        blastn_out=f"results_of_blastn_{primer3_config_display_name}/{threshold}/{{sample}}/blastn_results.gz"
    params:
        output_dir=f"results_of_blastn_{primer3_config_display_name}/{threshold}/{{sample}}/",
        script_path="scripts/blastn_ncbi_caller.py",
        threshold=threshold,
        config_file_name=blastn_config,
        target_db_filepath = target_db_filepath,
        taxon_ids=taxon_ids,
    resources:
        mem_mb=1024*8*2
    threads: 2
    shell:
        """
        export PATH=/home/harazono/miniconda3/bin:$PATH
        export LD_LIBRARY_PATH=~/miniconda3/pkgs/libffi-3.3-he6710b0_2/lib/:$LD_LIBRARY_PATH
        export BLASTDB=/usr/local/db/blast/ncbi/v5/
        python3 {params.script_path} {params.target_db_filepath} {params.taxon_ids} {input.fasta} {threads} -o {params.output_dir}
        """



# rule concatinate_blast_results:
#     input:
#         blastn_out=lambda wildcards: expand(f"results_of_blastn_{primer3_config_display_name}/{threshold}/{wildcards.sample}/each/{{db_name}}.blastn_out.gz",
#                                             db_name=[db.split("/")[-1] for db in tgt_db_names])
#     output:
#         blastn_out=f"results_of_blastn_{primer3_config_display_name}/{threshold}/{{sample}}/concatenated.blastn_out.gz"
#     resources:
#         mem_mb=1024*8*2
#     threads: 2
#     shell:
#         """
#         cat {input.blastn_out} > {output.blastn_out}
#         """


rule discard_cross_reactive_primers:
    input:
        blastn_out = f"results_of_blastn_{primer3_config_display_name}/{threshold}/{{sample}}/blastn_results.gz",
        fasta      = f"results_of_primer3_{primer3_config_display_name}_fasta/{threshold}/{threshold}_{{sample}}.fa",
        json       = f"results_of_primer3_{primer3_config_display_name}_json/{threshold}/{threshold}_{{sample}}.json",
    output:
        output_file_1 = f"results_of_discarding_{primer3_config_display_name}/{threshold}/{{sample}}/discard_results.finalist.tsv",
        output_file_2 = f"results_of_discarding_{primer3_config_display_name}/{threshold}/{{sample}}/discard_results.finalist_name.txt",
        output_file_3 = f"results_of_discarding_{primer3_config_display_name}/{threshold}/{{sample}}/discard_results.report",
    params:
        output_file = f"results_of_discarding_{primer3_config_display_name}/{threshold}/{{sample}}/discard_results",
        output_dir  = f"results_of_discarding_{primer3_config_display_name}/{threshold}/{{sample}}",
    resources:
        mem_mb=1024*16*8,
    threads: 8
    shell:
        """
        export PATH=/home/harazono/miniconda3/bin:$PATH
        export LD_LIBRARY_PATH=~/miniconda3/pkgs/libffi-3.3-he6710b0_2/lib/:$LD_LIBRARY_PATH
        mkdir -p {params.output_dir}
        python3 {discard_primes_path} {input.fasta} {input.blastn_out} {input.json} -o {params.output_file}
        """
